{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3354befa-4b0f-4e30-9758-1f6e77fd39ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误处理：加勒比地区 300 万美元的豪宅 - Invalid \\escape: line 54 column 148 (char 63844)\n",
      "加勒比地区 300 万美元的豪宅 ---- 发生错误，跳过该关键词。\n",
      "图片已保存到: D:\\我的文档\\我的代码\\爬虫\\爬虫\\智库下载图片2\\02_加勒比辣椒酱如何火起来\\1.jpg\n",
      "加勒比辣椒酱如何火起来 ---- 图像下载完成--------->\n",
      "图片已保存到: D:\\我的文档\\我的代码\\爬虫\\爬虫\\智库下载图片2\\03_巨型船舶之战？一艘欧洲巨无霸驶向加勒比海。\\1.jpg\n",
      "巨型船舶之战？一艘欧洲巨无霸驶向加勒比海。 ---- 图像下载完成--------->\n",
      "错误处理：从加利福尼亚到加勒比海：5 个阳光明媚的新度假胜地 - Invalid \\escape: line 14 column 158 (char 19069)\n",
      "从加利福尼亚到加勒比海：5 个阳光明媚的新度假胜地 ---- 发生错误，跳过该关键词。\n",
      "图片已保存到: D:\\我的文档\\我的代码\\爬虫\\爬虫\\智库下载图片2\\05_飓风席卷加勒比地区\\1.jpg\n",
      "飓风席卷加勒比地区 ---- 图像下载完成--------->\n",
      "图片已保存到: D:\\我的文档\\我的代码\\爬虫\\爬虫\\智库下载图片2\\06_古根海姆策展人将举办加勒比侨民展览\\1.jpg\n",
      "古根海姆策展人将举办加勒比侨民展览 ---- 图像下载完成--------->\n",
      "错误处理：克里斯托弗·哥伦布是否引发了气候危机？ - Invalid control character at: line 84 column 157 (char 42949)\n",
      "克里斯托弗·哥伦布是否引发了气候危机？ ---- 发生错误，跳过该关键词。\n",
      "图片已保存到: D:\\我的文档\\我的代码\\爬虫\\爬虫\\智库下载图片2\\08_邮轮公司改变行程以避开飓风海伦的影响\\1.jpg\n",
      "邮轮公司改变行程以避开飓风海伦的影响 ---- 图像下载完成--------->\n",
      "图片已保存到: D:\\我的文档\\我的代码\\爬虫\\爬虫\\智库下载图片2\\09_想看珊瑚礁生长吗？那就冷冻它们吧。\\1.jpg\n",
      "想看珊瑚礁生长吗？那就冷冻它们吧。 ---- 图像下载完成--------->\n",
      "图片已保存到: D:\\我的文档\\我的代码\\爬虫\\爬虫\\智库下载图片2\\10_飓风贝丽尔袭击东加勒比海后，正朝牙买加移动\\1.jpg\n",
      "飓风贝丽尔袭击东加勒比海后，正朝牙买加移动 ---- 图像下载完成--------->\n",
      "所有结果已保存到 '4测试.xlsx' 文件中。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from urllib import parse\n",
    "import os\n",
    "import time\n",
    "import pandas as pd  # 导入pandas库，用来读取和保存Excel文件\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "\n",
    "\n",
    "class BaiduImageSpider(object):\n",
    "    def __init__(self):\n",
    "        self.json_count = 1  # 每次请求获取1个json文件（即30张图片）\n",
    "        self.url = 'https://image.baidu.com/search/acjson?tn=resultjson_com&logid=5179920884740494226&ipn=rj&ct' \\\n",
    "                   '=201326592&is=&fp=result&queryWord={}&cl=2&lm=-1&ie=utf-8&oe=utf-8&adpicid=&st=-1&z=&ic=0&hd=1' \\\n",
    "                   '&latest=&copyright=&word={}&s=&se=&tab=&width=&height=&face=0&istype=2&qc=&nc=1&fr=&expermode=' \\\n",
    "                   '&nojc=&pn={}&rn=30&gsm=1e&1635054081427='  # 百度图片搜索的URL模板\n",
    "        self.header = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                          'Chrome/95.0.4638.54 Safari/537.36 Edg/95.0.1020.30 '\n",
    "        }\n",
    "        self.base_directory = os.path.join(os.getcwd(), \"智库下载图片2\")  # 创建一个总文件夹，存放所有图片\n",
    "        self.folder_counter = 1  # 用于生成按顺序编号的文件夹\n",
    "        self.image_paths = []  # 用来存储每个关键词的下载图片路径\n",
    "\n",
    "    # 创建总文件夹下的子文件夹，使用顺序编号和查询关键词作为文件夹名\n",
    "    def create_directory(self, name):\n",
    "        # 创建总文件夹（如果不存在）\n",
    "        if not os.path.exists(self.base_directory):\n",
    "            os.makedirs(self.base_directory)\n",
    "\n",
    "        # 使用编号和关键词来创建文件夹\n",
    "        folder_name = f\"{str(self.folder_counter).zfill(2)}_{name}\"  # 如：01_关键词\n",
    "        self.directory = os.path.join(self.base_directory, folder_name)\n",
    "\n",
    "        # 创建文件夹\n",
    "        if not os.path.exists(self.directory):\n",
    "            os.makedirs(self.directory)\n",
    "\n",
    "        # 更新文件夹编号\n",
    "        self.folder_counter += 1\n",
    "\n",
    "    # 获取图像链接，调整为只获取1张高清图片\n",
    "    def get_image_link(self, url):\n",
    "        list_image_link = []\n",
    "        try:\n",
    "            strhtml = requests.get(url, headers=self.header)\n",
    "            strhtml.raise_for_status()  # 检查HTTP请求是否成功\n",
    "            jsonInfo = json.loads(strhtml.text)\n",
    "            if 'data' in jsonInfo and jsonInfo['data']:\n",
    "                # 只取第一张图片\n",
    "                image_data = jsonInfo['data'][0]\n",
    "                if 'thumbURL' in image_data:  # 确保有图片链接\n",
    "                    list_image_link.append(image_data['thumbURL'])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"请求出错: {e}\")\n",
    "        return list_image_link\n",
    "\n",
    "    # 下载图片\n",
    "    def save_image(self, img_link, filename):\n",
    "        try:\n",
    "            res = requests.get(img_link, headers=self.header)\n",
    "            res.raise_for_status()  # 检查HTTP请求是否成功\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(res.content)\n",
    "                print(f\"图片已保存到: {filename}\")\n",
    "            return filename  # 返回保存的图片路径\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"图片下载出错: {e}\")\n",
    "            return None\n",
    "\n",
    "    # 处理每个关键词进行图片下载\n",
    "    def run(self, keywords, original_excel_file):\n",
    "        results = []  # 用来存储每个关键词的下载结果\n",
    "        for searchName in keywords:\n",
    "            searchName_parse = parse.quote(searchName)  # 对关键词进行编码\n",
    "\n",
    "            # 创建以查询内容为文件夹名的子目录，并添加编号\n",
    "            self.create_directory(searchName)\n",
    "\n",
    "            pic_number = 0  # 图像数量\n",
    "            found_images = False  # 标记是否找到图片\n",
    "            image_paths = []  # 用于存储当前关键词的图片路径\n",
    "\n",
    "            try:\n",
    "                for index in range(self.json_count):\n",
    "                    pn = (index) * 30  # 调整分页参数为1张图片\n",
    "                    request_url = self.url.format(searchName_parse, searchName_parse, str(pn))\n",
    "                    list_image_link = self.get_image_link(request_url)\n",
    "\n",
    "                    if list_image_link:  # 如果找到了图片链接\n",
    "                        found_images = True\n",
    "                        link = list_image_link[0]  # 只取第一张图片\n",
    "                        pic_number += 1\n",
    "                        # 存储图片到关键词文件夹\n",
    "                        image_path = self.save_image(link, os.path.join(self.directory, f'{pic_number}.jpg'))\n",
    "                        if image_path:\n",
    "                            image_paths.append(image_path)  # 将下载的图片路径添加到列表\n",
    "                        time.sleep(0.5)  # 休眠0.5秒，防止封IP\n",
    "\n",
    "                # 记录下载结果\n",
    "                if found_images:\n",
    "                    results.append([searchName] + image_paths)  # 存储关键词和图片路径\n",
    "                    print(f\"{searchName} ---- 图像下载完成--------->\")\n",
    "                else:\n",
    "                    results.append([searchName, '未找到图片'])  # 如果未找到图片\n",
    "                    print(f\"{searchName} ---- 未找到图片，已跳过。\")\n",
    "\n",
    "            except Exception as e:\n",
    "                # 捕获所有异常并处理\n",
    "                print(f\"错误处理：{searchName} - {e}\")\n",
    "                # 即使发生错误，也将结果记录为未找到图片并跳过\n",
    "                results.append([searchName, '下载失败'])\n",
    "                print(f\"{searchName} ---- 发生错误，跳过该关键词。\")\n",
    "\n",
    "        # 保存结果到Excel文件并插入图片\n",
    "        self.save_to_excel(results, original_excel_file)\n",
    "\n",
    "    # 将结果保存到Excel文件并插入图片\n",
    "    def save_to_excel(self, results, original_excel_file):\n",
    "        # 读取原始Excel文件\n",
    "        df = pd.read_excel(original_excel_file)\n",
    "\n",
    "        # 创建一个新的Excel工作簿\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "\n",
    "        # 设置标题行，保留原始数据列\n",
    "        header = df.columns.tolist() + ['图片1']\n",
    "        ws.append(header)\n",
    "\n",
    "        # 遍历每个关键词的结果\n",
    "        for i, result in enumerate(results):\n",
    "            keyword = result[0]\n",
    "            image_paths = result[1:]\n",
    "\n",
    "            # 获取原始文件中的一行数据\n",
    "            original_row = df.iloc[i].tolist()\n",
    "\n",
    "            # 向Excel中插入原始数据和图片路径\n",
    "            ws.append(original_row + [''] * (5 - len(image_paths)))  # 保证每个关键词都有1个单元格\n",
    "\n",
    "            # 向单元格中插入图片\n",
    "            if image_paths:\n",
    "                image_path = image_paths[0]  # 取第一张图片\n",
    "                if image_path and os.path.exists(image_path):\n",
    "                    img = Image(image_path)\n",
    "                    img.width = 100  # 设置图片宽度\n",
    "                    img.height = 100  # 设置图片高度\n",
    "                    cell = ws.cell(row=ws.max_row, column=len(original_row) + 1)  # 图片插入到对应列\n",
    "                    ws.add_image(img, cell.coordinate)\n",
    "\n",
    "        # 保存最终结果到Excel文件\n",
    "        output_filename = f\"4测试.xlsx\"\n",
    "        wb.save(output_filename)\n",
    "        print(f\"所有结果已保存到 '{output_filename}' 文件中。\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 读取Excel文件中的关键词列表\n",
    "    excel_file = r\"C:\\Users\\86155\\Desktop\\学习\\6.xlsx\"  # 替换为你的Excel文件路径\n",
    "    df = pd.read_excel(excel_file)  # 读取Excel文件\n",
    "    keywords = df.iloc[:, 0].tolist()  # 假设关键词存储在第三列\n",
    "\n",
    "    spider = BaiduImageSpider()\n",
    "    spider.json_count = 1  # 设置每次只下载1张图片\n",
    "    spider.run(keywords, excel_file)  # 传入从Excel读取的关键词列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c86b9-0742-4d71-a904-20c775f975c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
